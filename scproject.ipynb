{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os \n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     lesion_id      image_id   dx dx_type   age     sex localization\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0    male        scalp\n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0    male        scalp\n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0    male        scalp\n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0    male        scalp\n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0    male          ear\n",
      "5  HAM_0001466  ISIC_0027850  bkl   histo  75.0    male          ear\n",
      "6  HAM_0002761  ISIC_0029176  bkl   histo  60.0    male         face\n",
      "7  HAM_0002761  ISIC_0029068  bkl   histo  60.0    male         face\n",
      "8  HAM_0005132  ISIC_0025837  bkl   histo  70.0  female         back\n",
      "9  HAM_0005132  ISIC_0025209  bkl   histo  70.0  female         back\n",
      "           image_id     dx\n",
      "0      ISIC_0027419    bkl\n",
      "1      ISIC_0025030    bkl\n",
      "2      ISIC_0026769    bkl\n",
      "3      ISIC_0025661    bkl\n",
      "4      ISIC_0031633    bkl\n",
      "5      ISIC_0027850    bkl\n",
      "6      ISIC_0029176    bkl\n",
      "7      ISIC_0029068    bkl\n",
      "8      ISIC_0025837    bkl\n",
      "9      ISIC_0025209    bkl\n",
      "10     ISIC_0025276    bkl\n",
      "11     ISIC_0029396    bkl\n",
      "12     ISIC_0025984    bkl\n",
      "13     ISIC_0025767    bkl\n",
      "14     ISIC_0032417    bkl\n",
      "15     ISIC_0031326    bkl\n",
      "16     ISIC_0025915    bkl\n",
      "17     ISIC_0031029    bkl\n",
      "18     ISIC_0029836    bkl\n",
      "19     ISIC_0032129    bkl\n",
      "20     ISIC_0032343    bkl\n",
      "21     ISIC_0025033    bkl\n",
      "22     ISIC_0027310    bkl\n",
      "23     ISIC_0032128    bkl\n",
      "24     ISIC_0025937    bkl\n",
      "25     ISIC_0027828    bkl\n",
      "26     ISIC_0029291    bkl\n",
      "27     ISIC_0030698    bkl\n",
      "28     ISIC_0025567    bkl\n",
      "29     ISIC_0031753    bkl\n",
      "...             ...    ...\n",
      "9985   ISIC_0027884  akiec\n",
      "9986   ISIC_0028517  akiec\n",
      "9987   ISIC_0031108  akiec\n",
      "9988   ISIC_0027588  akiec\n",
      "9989   ISIC_0029025  akiec\n",
      "9990   ISIC_0027334  akiec\n",
      "9991   ISIC_0030133  akiec\n",
      "9992   ISIC_0033811  akiec\n",
      "9993   ISIC_0026650  akiec\n",
      "9994   ISIC_0030877  akiec\n",
      "9995   ISIC_0027950  akiec\n",
      "9996   ISIC_0027615  akiec\n",
      "9997   ISIC_0028990  akiec\n",
      "9998   ISIC_0033358  akiec\n",
      "9999   ISIC_0030655  akiec\n",
      "10000  ISIC_0033151  akiec\n",
      "10001  ISIC_0031922  akiec\n",
      "10002  ISIC_0032947  akiec\n",
      "10003  ISIC_0029141  akiec\n",
      "10004  ISIC_0029309  akiec\n",
      "10005  ISIC_0028393  akiec\n",
      "10006  ISIC_0024948  akiec\n",
      "10007  ISIC_0028619  akiec\n",
      "10008  ISIC_0033705  akiec\n",
      "10009  ISIC_0031430  akiec\n",
      "10010  ISIC_0033084  akiec\n",
      "10011  ISIC_0033550  akiec\n",
      "10012  ISIC_0033536  akiec\n",
      "10013  ISIC_0032854  akiec\n",
      "10014  ISIC_0032258    mel\n",
      "\n",
      "[10015 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"HAM10000_metadata.csv\")[:10]\n",
    "print(metadata)\n",
    "df = pd.read_csv(\"HAM10000_metadata.csv\",usecols=[1,2])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          image_id   dx\n",
      "0     ISIC_0027419  bkl\n",
      "1     ISIC_0025030  bkl\n",
      "2     ISIC_0026769  bkl\n",
      "3     ISIC_0025661  bkl\n",
      "4     ISIC_0031633  bkl\n",
      "5     ISIC_0027850  bkl\n",
      "6     ISIC_0029176  bkl\n",
      "7     ISIC_0029068  bkl\n",
      "8     ISIC_0025837  bkl\n",
      "9     ISIC_0025209  bkl\n",
      "10    ISIC_0025276  bkl\n",
      "11    ISIC_0029396  bkl\n",
      "12    ISIC_0025984  bkl\n",
      "13    ISIC_0025767  bkl\n",
      "14    ISIC_0032417  bkl\n",
      "15    ISIC_0031326  bkl\n",
      "16    ISIC_0025915  bkl\n",
      "17    ISIC_0031029  bkl\n",
      "18    ISIC_0029836  bkl\n",
      "19    ISIC_0032129  bkl\n",
      "20    ISIC_0032343  bkl\n",
      "21    ISIC_0025033  bkl\n",
      "22    ISIC_0027310  bkl\n",
      "23    ISIC_0032128  bkl\n",
      "24    ISIC_0025937  bkl\n",
      "25    ISIC_0027828  bkl\n",
      "26    ISIC_0029291  bkl\n",
      "27    ISIC_0030698  bkl\n",
      "28    ISIC_0025567  bkl\n",
      "29    ISIC_0031753  bkl\n",
      "...            ...  ...\n",
      "1070  ISIC_0027428  bkl\n",
      "1071  ISIC_0026446  bkl\n",
      "1072  ISIC_0026262  bkl\n",
      "1073  ISIC_0026416  bkl\n",
      "1074  ISIC_0029048  bkl\n",
      "1075  ISIC_0025431  bkl\n",
      "1076  ISIC_0027332  bkl\n",
      "1077  ISIC_0029741  bkl\n",
      "1078  ISIC_0028925  bkl\n",
      "1079  ISIC_0026556  bkl\n",
      "1080  ISIC_0031362  bkl\n",
      "1081  ISIC_0026941  bkl\n",
      "1082  ISIC_0025654  bkl\n",
      "1083  ISIC_0025387  bkl\n",
      "1084  ISIC_0027027  bkl\n",
      "1085  ISIC_0029036  bkl\n",
      "1086  ISIC_0029880  bkl\n",
      "1087  ISIC_0025484  bkl\n",
      "1088  ISIC_0030488  bkl\n",
      "1089  ISIC_0031761  bkl\n",
      "1090  ISIC_0030583  bkl\n",
      "1091  ISIC_0026042  bkl\n",
      "1092  ISIC_0028797  bkl\n",
      "1093  ISIC_0027326  bkl\n",
      "1094  ISIC_0030789  bkl\n",
      "3326  ISIC_0025366  bkl\n",
      "7100  ISIC_0028977  bkl\n",
      "9546  ISIC_0032655  bkl\n",
      "9630  ISIC_0033620  bkl\n",
      "9631  ISIC_0034040  bkl\n",
      "\n",
      "[1099 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_bkl = df[df['dx']==\"bkl\"]\n",
    "print(df_bkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1099\n"
     ]
    }
   ],
   "source": [
    "df_bkl_img = df_bkl.image_id.tolist()\n",
    "img_bkl = []\n",
    "for i in range(len(df_bkl_img)):\n",
    "    img_bkl.append(df_bkl_img[i]+\".jpg\")\n",
    "print(len(img_bkl))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"HAM10000_images_part_1\"\n",
    "dest = \"bkl\"\n",
    "for t in img_bkl:\n",
    "    shutil.move(src+\"/\"+t,dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "dis = [\"akiec\",\"bcc\",\"df\",\"mel\",\"nv\",\"vasc\"]\n",
    "\n",
    "df = pd.read_csv(\"HAM10000_metadata.csv\",usecols=[1,2])\n",
    "df_bkl = df[df['dx']==\"vasc\"]\n",
    "df_bkl_img = df_bkl.image_id.tolist()\n",
    "img_bkl = []\n",
    "for i in range(len(df_bkl_img)):\n",
    "    img_bkl.append(df_bkl_img[i]+\".jpg\")\n",
    "print(len(img_bkl))\n",
    "src = \"HAM10000_images_part_1\"\n",
    "dest = \"vasc\"\n",
    "for t in img_bkl:\n",
    "    shutil.move(src+\"/\"+t,dest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "def splitdata(source,train_dest,test_dest,SPLIT_SIZE):\n",
    "    files = os.listdir(source)\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[-testing_length:]\n",
    "    for t in training_set:\n",
    "        shutil.move(source+\"/\"+t,train_dest)\n",
    "    for t in testing_set:\n",
    "        shutil.move(source+\"/\"+t,test_dest)\n",
    "dis = [\"akiec\",\"bcc\",\"bkl\",\"mel\",\"nv\",\"vasc\"]\n",
    "\n",
    "\n",
    "splitdata(\"akiec\",\"train/akiec\",\"test/akiec\",0.9)\n",
    "splitdata(\"bcc\",\"train/bcc\",\"test/bcc\",0.9)\n",
    "splitdata(\"bkl\",\"train/bkl\",\"test/bkl\",0.9)\n",
    "splitdata(\"mel\",\"train/mel\",\"test/mel\",0.9)\n",
    "splitdata(\"nv\",\"train/nv\",\"test/nv\",0.9)\n",
    "splitdata(\"vasc\",\"train/vasc\",\"test/vasc\",0.9)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 98, 98, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 49, 49, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 47, 47, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 3,304,487\n",
      "Trainable params: 3,304,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(100,100,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"sgd\", loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = \"train\"\n",
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                   rotation_range=30, \n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   brightness_range=, \n",
    "                                   shear_range=0.3, \n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=50,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(100,100))\n",
    "\n",
    "VALIDATION_DIR = \"test\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                       rotation_range=30, \n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       brightness_range=, \n",
    "                                       shear_range=0.3, \n",
    "                                       zoom_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True)\n",
    "validation_genertor = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                  batch_size=50,\n",
    "                                                  class_mode='categorical',\n",
    "                                                target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=5, epochs = 50,\n",
    "  verbose = 1,validation_data = validation_genertor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
